---
tags: RAG,FAISS,向量检索,AI技术
language: zh-CN
---

## 什么是 RAG？

**RAG（Retrieval-Augmented Generation，检索增强生成）** 是一种将信息检索与大语言模型（LLM）结合的技术范式。它解决了纯 LLM 的两个核心问题：

1. **知识时效性**：LLM 训练数据有截止日期，无法获取最新信息
2. **幻觉问题**：LLM 可能生成看似合理但实际错误的内容

### RAG 的工作流程

```
用户提问
   ↓
① 向量化查询（Embedding）
   ↓
② 在向量数据库中检索相关文档（FAISS）
   ↓
③ 将检索结果作为上下文注入 Prompt
   ↓
④ LLM 基于上下文生成回答（Gemini）
   ↓
返回给用户
```

### Pool AI Knowledge 中的实现

在本项目中，RAG 管线的实现如下：

#### 文档嵌入阶段

```python
# 每篇文章转为文本："标题. 正文内容"
# 使用 OpenAI text-embedding-ada-002 模型生成向量
# 向量存入 FAISS 内存索引
```

- 嵌入维度：1536 维
- 索引类型：FAISS IndexFlatL2（精确 L2 距离搜索）
- 触发时机：服务启动时全量构建，文章增删改时增量更新

#### 检索阶段

- 用户查询同样经过 Embedding 转为向量
- FAISS 执行 top-k 近邻搜索（默认 k=3）
- 返回最相关的文章内容

#### 生成阶段

- 检索到的文档内容注入到 Gemini Agent 的 Prompt 中
- Agent 根据上下文生成结构化、准确的回答
- 如果知识库中没有相关内容，Agent 会诚实告知

### 为什么选择 FAISS？

| 特性 | FAISS | 传统数据库 |
|------|-------|-----------|
| 搜索方式 | 语义相似度 | 关键词匹配 |
| 搜索速度 | 毫秒级（内存） | 取决于索引 |
| 理解能力 | 理解语义和意图 | 仅字面匹配 |
| 适用场景 | 智能问答、推荐 | 精确查询 |

### 最佳实践

1. **内容质量**：文章内容越详细、结构化越好，检索效果越佳
2. **合理分段**：将长文档拆分为独立主题的短文章
3. **多语言分开**：不同语言的内容使用对应的语言标签
4. **定期更新**：保持知识库内容的时效性和准确性
